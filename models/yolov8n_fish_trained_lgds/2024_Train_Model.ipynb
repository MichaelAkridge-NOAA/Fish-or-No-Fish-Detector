{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YesCg-LraWJe"
   },
   "source": [
    "### Download Data - requires Google SDK tool GSUTIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsutil -m rsync -r gs://nmfs_odp_pifsc/PIFSC/SOD/MOUSS/jpg/20161014_192048_1 U:\\temp\\20161014_192048_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg41uZvaZ3wO"
   },
   "source": [
    "# Yolo8n Training -\n",
    "## Unsupervised training of Yolo8n (nano) model with Yolo8x large model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJ5DnFdF6QdY",
    "outputId": "e2acb820-af35-40bd-8144-1fc709f8726d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "unzipped_folder = r\"V:\\temp\\20161014_192048_1\"  # Use raw string for Windows paths\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is properly set up\n",
    "print(torch.version.cuda)  # Prints the version of CUDA PyTorch is using\n",
    "print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "print(f\"GPU Name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "\n",
    "# Step 3: Check if CUDA is available and load the large model (YOLOv8x) to CUDA if possible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the large model (YOLOv8x) that was fine-tuned for VME detection\n",
    "large_model = YOLO(r\"V:\\temp\\models\\best.pt\")  # Update to your model path\n",
    "large_model = large_model.to(device)  # Move the model to GPU (CUDA) if available\n",
    "\n",
    "# Step 4: Create folders for the new dataset (images and labels)\n",
    "base_path = r\"V:\\temp\\lg_fish_dataset\"\n",
    "\n",
    "# Create directories for train/val images and labels\n",
    "os.makedirs(os.path.join(base_path, \"images\", \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_path, \"images\", \"val\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_path, \"labels\", \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_path, \"labels\", \"val\"), exist_ok=True)\n",
    "\n",
    "# Step 5: Define the input folder containing the original images (unzipped)\n",
    "input_images_folder = unzipped_folder\n",
    "image_paths = [os.path.join(input_images_folder, img) for img in os.listdir(input_images_folder) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Split images into train and validation (80% train, 20% validation)\n",
    "train_images = image_paths[:int(0.8 * len(image_paths))]\n",
    "val_images = image_paths[int(0.8 * len(image_paths)):]\n",
    "\n",
    "# Function to save YOLO format labels (class_id x_center y_center width height)\n",
    "def save_yolo_labels(label_path, class_id, bbox, image_width, image_height):\n",
    "    if bbox is not None and len(bbox) > 0:  # Ensure there are bounding boxes\n",
    "        x_center = (bbox[0] + bbox[2]) / 2 / image_width\n",
    "        y_center = (bbox[1] + bbox[3]) / 2 / image_height\n",
    "        width = (bbox[2] - bbox[0]) / image_width\n",
    "        height = (bbox[3] - bbox[1]) / image_height\n",
    "        with open(label_path, \"a\") as f:\n",
    "            f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "        print(f\"Label saved for {label_path}: {class_id} {x_center} {y_center} {width} {height}\")\n",
    "    else:\n",
    "        print(f\"No bounding boxes found for {label_path}, skipping label.\")\n",
    "\n",
    "# Function to process images, run inference, and save results\n",
    "def process_images(image_paths, split):\n",
    "    for image_path in image_paths:\n",
    "        # Step 6: Run the large model to detect objects in the image (with GPU if available)\n",
    "        results = large_model(image_path)\n",
    "\n",
    "        # Check if any instances were detected\n",
    "        print(f\"Processing {image_path}, found {len(results[0].boxes)} instances.\")\n",
    "\n",
    "        # Extract image dimensions\n",
    "        img_name = os.path.basename(image_path)\n",
    "        img = results[0].orig_img\n",
    "        img_height, img_width = img.shape[:2]\n",
    "\n",
    "        # Save the image to the appropriate split folder (train/val)\n",
    "        output_image_path = os.path.join(base_path, \"images\", split, img_name)\n",
    "        os.rename(image_path, output_image_path)\n",
    "\n",
    "        # Step 7: Filter results to only include \"fish\" category (class_id = 2)\n",
    "        fish_class_index = 2  # Assuming fish is class 2 in the large model\n",
    "        for result in results:\n",
    "            for i, cls in enumerate(result.boxes.cls):\n",
    "                if cls == fish_class_index:  # Only keep fish detections\n",
    "                    bbox = result.boxes.xyxy[i].cpu().numpy()  # Bounding box (x1, y1, x2, y2)\n",
    "                    print(f\"Detected fish with bounding box: {bbox}\")\n",
    "                    print(f\"Image dimensions: {img_width}x{img_height}\")\n",
    "\n",
    "                    # Step 8: Save label file in YOLO format\n",
    "                    label_name = img_name.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "                    label_path = os.path.join(base_path, \"labels\", split, label_name)\n",
    "\n",
    "                    # Save the bounding box in YOLO format (class_id = 0 for fish)\n",
    "                    save_yolo_labels(label_path, class_id=0, bbox=bbox, image_width=img_width, image_height=img_height)\n",
    "\n",
    "# Step 9: Process all training and validation images\n",
    "print(\"Processing all training images...\")\n",
    "process_images(train_images, \"train\")\n",
    "\n",
    "print(\"Processing all validation images...\")\n",
    "process_images(val_images, \"val\")\n",
    "\n",
    "# Step 10: Create a YAML file for the dataset\n",
    "fish_dataset_yaml = f\"\"\"\n",
    "train: \"{base_path}/images/train\"\n",
    "val: \"{base_path}/images/val\"\n",
    "\n",
    "# Number of classes\n",
    "nc: 1\n",
    "\n",
    "# Class names\n",
    "names: ['Fish']\n",
    "\"\"\"\n",
    "\n",
    "# Save the YAML file\n",
    "yaml_file_path = os.path.join(base_path, \"fish_dataset.yaml\")\n",
    "with open(yaml_file_path, \"w\") as yaml_file:\n",
    "    yaml_file.write(fish_dataset_yaml)\n",
    "\n",
    "print(f\"YAML file created: {yaml_file_path}\")\n",
    "\n",
    "# Step 11: Train the YOLOv8n model using the generated dataset\n",
    "small_model = YOLO(\"yolov8n.pt\")  # Load the smaller YOLOv8n model\n",
    "\n",
    "# Train the model using the generated fish-only dataset\n",
    "small_model.train(data=yaml_file_path, epochs=50, imgsz=416, batch=16, lr0=0.001)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "# Save the model\n",
    "small_model.save(r\"V:\\temp\\yolov8n_fish_trained_lgds.pt\")\n",
    "\n",
    "# Evaluate model performance\n",
    "metrics = small_model.val(data=yaml_file_path)  # Evaluate precision, recall, and mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "YAML file created: V:\\temp\\lg_fish_dataset\\fish_dataset.yaml\n",
      "Ultralytics YOLOv8.2.95  Python-3.10.14 torch-2.4.1+cu118 CUDA:0 (Quadro P4000, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=V:\\temp\\lg_fish_dataset\\fish_dataset.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train3\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\PICHLMRUser\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 2.40MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning \\\\PICQUEENFISH\\OPTICAL\\temp\\lg_fish_dataset\\labels\\train... 8466 images, 10262 backgrounds, 0 corrupt: 100%|██████████| 18728/18728 [00:16<00:00, 1107.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: \\\\PICQUEENFISH\\OPTICAL\\temp\\lg_fish_dataset\\labels\\train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning \\\\PICQUEENFISH\\OPTICAL\\temp\\lg_fish_dataset\\labels\\val... 2721 images, 1961 backgrounds, 0 corrupt: 100%|██████████| 4682/4682 [00:04<00:00, 1028.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: \\\\PICQUEENFISH\\OPTICAL\\temp\\lg_fish_dataset\\labels\\val.cache\n",
      "Plotting labels to runs\\detect\\train3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      1.27G      1.128      1.843      1.135         12        416: 100%|██████████| 1171/1171 [02:56<00:00,  6.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:21<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.644      0.608      0.651      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      1.28G      1.102      1.202      1.127         10        416: 100%|██████████| 1171/1171 [02:50<00:00,  6.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:21<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.636       0.69      0.685      0.425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      1.28G       1.19      1.145      1.186         18        416: 100%|██████████| 1171/1171 [02:47<00:00,  6.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.649      0.665      0.672      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      1.27G      1.188      1.107      1.204         16        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:21<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.667      0.661      0.698      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      1.26G      1.124      1.024      1.171         10        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:21<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.669      0.689      0.705      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      1.26G      1.068     0.9666      1.143          6        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.727      0.696      0.771       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      1.26G      1.037     0.9383       1.13         12        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:21<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.735      0.715      0.769      0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      1.26G     0.9982     0.9005      1.115          3        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.707      0.691      0.742      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      1.25G     0.9844     0.8832      1.114          6        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:21<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.731      0.743      0.776      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      1.27G     0.9616     0.8695      1.102         10        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335       0.73      0.734      0.779       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      1.26G     0.9417     0.8446      1.089         13        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.707      0.733      0.768      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      1.27G     0.9307     0.8411       1.09         13        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.752      0.734      0.796      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      1.25G     0.9093     0.8251      1.075         13        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.739      0.756      0.808      0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      1.27G     0.9036     0.8145      1.073         12        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.749      0.739      0.797      0.582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      1.26G     0.8899     0.8045      1.064          7        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.735      0.759      0.798      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      1.26G     0.8759      0.795      1.058          7        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.754      0.753      0.809      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      1.25G     0.8738     0.7894      1.057          9        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.747      0.741      0.798        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      1.27G     0.8631      0.782      1.056          9        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.759      0.755      0.814      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      1.26G     0.8495     0.7641       1.05         11        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.761      0.746      0.817      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      1.26G     0.8473     0.7618      1.048          4        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.736      0.764      0.812      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      1.25G     0.8392     0.7457      1.046         10        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:22<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.773      0.744      0.818      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      1.27G     0.8333     0.7442      1.039         11        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335       0.77      0.737      0.819      0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      1.27G      0.825     0.7337      1.032         16        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.757      0.748      0.821       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      1.26G     0.8206     0.7351      1.033         12        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.774      0.756       0.83       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      1.25G     0.8084      0.722      1.028          3        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.763      0.752      0.825      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      1.27G     0.8019     0.7152      1.025          6        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335       0.77      0.765      0.825      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      1.27G     0.7926     0.7027      1.018         14        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.765      0.763       0.82      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      1.26G     0.7876     0.6944      1.021         17        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335       0.78      0.744      0.832      0.636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      1.25G     0.7808     0.7005      1.018         11        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.784       0.75      0.833      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      1.26G     0.7751     0.6936      1.012          8        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.775      0.758      0.831      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      1.26G     0.7685     0.6909      1.014          6        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335       0.78      0.753      0.835       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      1.26G     0.7587     0.6763      1.007          4        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.798      0.744      0.831      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      1.25G     0.7584     0.6825      1.009         17        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.776      0.759      0.833      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      1.26G     0.7485     0.6682      1.006          7        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335       0.78      0.756      0.834      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      1.26G     0.7426     0.6621      1.002         13        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.767      0.769      0.835      0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      1.27G     0.7427     0.6554          1         13        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.779      0.763      0.837      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      1.25G     0.7308      0.649      0.996         17        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.778      0.767      0.837       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      1.27G     0.7336     0.6494     0.9999         10        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.783      0.762      0.839      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      1.26G     0.7219     0.6377     0.9921          8        416: 100%|██████████| 1171/1171 [02:46<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.786      0.756      0.838       0.65\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      1.26G      0.716     0.6328     0.9927          8        416: 100%|██████████| 1171/1171 [02:47<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.781      0.761      0.837       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      1.25G     0.6062     0.5525     0.9198          7        416: 100%|██████████| 1171/1171 [02:44<00:00,  7.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.775      0.764      0.837      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      1.26G     0.5953     0.5414     0.9206          4        416: 100%|██████████| 1171/1171 [02:44<00:00,  7.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335       0.78      0.764      0.839      0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      1.26G     0.5872     0.5355     0.9158          4        416: 100%|██████████| 1171/1171 [02:44<00:00,  7.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.779      0.762      0.837      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      1.26G     0.5786     0.5236     0.9084          6        416: 100%|██████████| 1171/1171 [02:45<00:00,  7.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335       0.78       0.76      0.837      0.653\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      1.25G     0.5621     0.5109     0.9059          8        416: 100%|██████████| 1171/1171 [02:45<00:00,  7.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.776      0.763      0.838      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      1.27G     0.5616     0.5056      0.904          8        416: 100%|██████████| 1171/1171 [02:45<00:00,  7.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.779      0.758      0.838      0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      1.26G     0.5576     0.5042     0.9011          4        416: 100%|██████████| 1171/1171 [02:45<00:00,  7.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.775      0.759      0.838      0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      1.26G     0.5476     0.4893     0.8987         11        416: 100%|██████████| 1171/1171 [02:45<00:00,  7.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335       0.78      0.755      0.837      0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      1.25G      0.539     0.4831     0.8962          7        416: 100%|██████████| 1171/1171 [02:45<00:00,  7.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.784       0.75      0.837      0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      1.26G     0.5382     0.4771      0.899          3        416: 100%|██████████| 1171/1171 [02:45<00:00,  7.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:20<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.773       0.76      0.838      0.655\n",
      "\n",
      "50 epochs completed in 2.627 hours.\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.95  Python-3.10.14 torch-2.4.1+cu118 CUDA:0 (Quadro P4000, 8192MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:21<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335      0.779      0.758      0.838      0.655\n",
      "Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Training complete!\n",
      "Ultralytics YOLOv8.2.95  Python-3.10.14 torch-2.4.1+cu118 CUDA:0 (Quadro P4000, 8192MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning \\\\PICQUEENFISH\\OPTICAL\\temp\\lg_fish_dataset\\labels\\val.cache... 2721 images, 1961 backgrounds, 0 corrupt: 100%|██████████| 4682/4682 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 293/293 [00:22<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4682       5335       0.78      0.758      0.838      0.656\n",
      "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train32\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "unzipped_folder = r\"V:\\temp\\20161014_192048_1\"  # Use raw string for Windows paths\n",
    "\n",
    "# Step 3: Check if CUDA is available and load the large model (YOLOv8x) to CUDA if possible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the large model (YOLOv8x) that was fine-tuned for VME detection\n",
    "large_model = YOLO(r\"V:\\temp\\models\\best.pt\")  # Update to your model path\n",
    "large_model = large_model.to(device)  # Move the model to GPU (CUDA) if available\n",
    "\n",
    "# Step 4: Create folders for the new dataset (images and labels)\n",
    "base_path = r\"V:\\temp\\lg_fish_dataset\"\n",
    "\n",
    "\n",
    "# Step 10: Create a YAML file for the dataset\n",
    "fish_dataset_yaml = f\"\"\"\n",
    "train: \"V:/temp/lg_fish_dataset/images/train\"\n",
    "val: \"V:/temp/lg_fish_dataset/images/val\"\n",
    "\n",
    "# Number of classes\n",
    "nc: 1\n",
    "\n",
    "# Class names\n",
    "names: ['Fish']\n",
    "\"\"\"\n",
    "\n",
    "# Save the YAML file\n",
    "yaml_file_path = os.path.join(base_path, \"fish_dataset.yaml\")\n",
    "with open(yaml_file_path, \"w\") as yaml_file:\n",
    "    yaml_file.write(fish_dataset_yaml)\n",
    "\n",
    "print(f\"YAML file created: {yaml_file_path}\")\n",
    "\n",
    "\n",
    "# Step 11: Train the YOLOv8n model using the generated dataset\n",
    "small_model = YOLO(\"yolov8n.pt\")  # Load the smaller YOLOv8n model\n",
    "\n",
    "# Train the model using the generated fish-only dataset\n",
    "small_model.train(data=yaml_file_path, epochs=50, imgsz=416, batch=16, lr0=0.001)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "# Save the model\n",
    "small_model.save(r\"V:\\temp\\yolov8n_fish_trained_lgds.pt\")\n",
    "\n",
    "# Evaluate model performance\n",
    "metrics = small_model.val(data=yaml_file_path)  # Evaluate precision, recall, and mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FR-Y3oydaYZt"
   },
   "source": [
    "### Start Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_IBNFv7m__YG",
    "outputId": "a3ad4496-d3d3-43ac-e94a-e4d45e1c9970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.93 🚀 Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/fish_dataset/labels/val.cache... 337 images, 32 backgrounds, 0 corrupt: 100%|██████████| 369/369 [00:00<?, ?it/s]\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:04<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        369        473      0.863      0.869      0.936      0.856\n",
      "Speed: 0.1ms preprocess, 2.5ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train22\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = small_model.val(data=\"/content/fish_dataset.yaml\")  # This will evaluate precision, recall, and mAP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFcGFuT0ZxhG"
   },
   "source": [
    "## Test Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhG-erbv9Biz",
    "outputId": "5811fdc4-2303-4e70-8248-c54c5db44d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing a small sample of training images to test label generation...\n",
      "\n",
      "image 1/1 /content/original/original/01649.jpg: 512x640 1 Fish, 69.2ms\n",
      "Speed: 3.2ms preprocess, 69.2ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processing /content/original/original/01649.jpg, found 1 instances.\n",
      "Detected fish with bounding box: [     175.25      150.98      378.53      304.93]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/01649.txt: 0 0.286039967182254 0.31312393356155566 0.21000108640056012 0.21146348806527945\n",
      "\n",
      "image 1/1 /content/original/original/00381.jpg: 512x640 2 Fishs, 43.9ms\n",
      "Speed: 2.2ms preprocess, 43.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processing /content/original/original/00381.jpg, found 2 instances.\n",
      "Detected fish with bounding box: [      103.2      167.75      311.31      326.53]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/00381.txt: 0 0.21410467604960293 0.3394819825560182 0.21499066313436208 0.21810340881347656\n",
      "Detected fish with bounding box: [     264.21      287.18      347.54      375.26]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/00381.txt: 0 0.31598625498369703 0.45497626000708274 0.08607530199791774 0.12098710615556318\n",
      "\n",
      "image 1/1 /content/original/original/00490.jpg: 512x640 2 Fishs, 44.0ms\n",
      "Speed: 2.2ms preprocess, 44.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processing /content/original/original/00490.jpg, found 2 instances.\n",
      "Detected fish with bounding box: [      189.4      127.22      397.04      269.02]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/00490.txt: 0 0.30290877917581355 0.27214314387394833 0.21450468331329092 0.19479051527086194\n",
      "Detected fish with bounding box: [    0.60938           0      370.87      144.29]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/00490.txt: 0 0.19187875227494675 0.09909770252940418 0.38249846529369513 0.19819540505880837\n",
      "\n",
      "image 1/1 /content/original/original/00689.jpg: 512x640 1 Fish, 43.6ms\n",
      "Speed: 3.6ms preprocess, 43.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processing /content/original/original/00689.jpg, found 1 instances.\n",
      "Detected fish with bounding box: [     199.43      134.48      331.65      398.19]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/00689.txt: 0 0.2743160783751937 0.3658408699454842 0.13659128866905024 0.36224130483774036\n",
      "\n",
      "image 1/1 /content/original/original/01046.jpg: 512x640 2 Fishs, 42.4ms\n",
      "Speed: 2.1ms preprocess, 42.4ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processing /content/original/original/01046.jpg, found 2 instances.\n",
      "Detected fish with bounding box: [     379.73      234.44      455.42      285.21]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/01046.txt: 0 0.4313812886387849 0.356903076171875 0.07819177296536028 0.0697359147962633\n",
      "Detected fish with bounding box: [     388.79      344.38      447.39      381.68]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/01046.txt: 0 0.4319138645140593 0.49866741306179174 0.06054019139817923 0.051239768227378094\n",
      "Generated labels for training set: ['01046.txt', '00490.txt', '00381.txt', '00689.txt', '01649.txt']\n",
      "Test complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import py7zr\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Step 1: Install Ultralytics YOLOv8 and py7zr (if not already installed)\n",
    "#!pip install ultralytics py7zr\n",
    "\n",
    "# Define the folder path\n",
    "unzipped_folder = \"/content/original/original\"\n",
    "\n",
    "# Step 3: Check if CUDA is available and load the large model (YOLOv8x) to CUDA if possible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the large model (YOLOv8x) that was fine-tuned for VME detection\n",
    "large_model = YOLO(\"/content/best.pt\")  # Replace with your model path\n",
    "large_model = large_model.to(device)  # Move the model to GPU (CUDA) if available\n",
    "\n",
    "# Step 4: Create folders for the new dataset (images and labels)\n",
    "base_path = \"/content/fish_dataset\"\n",
    "\n",
    "# Create directories for train/val images and labels\n",
    "os.makedirs(f\"{base_path}/images/train\", exist_ok=True)\n",
    "os.makedirs(f\"{base_path}/images/val\", exist_ok=True)\n",
    "os.makedirs(f\"{base_path}/labels/train\", exist_ok=True)\n",
    "os.makedirs(f\"{base_path}/labels/val\", exist_ok=True)\n",
    "\n",
    "# Step 5: Define the input folder containing the original images (unzipped)\n",
    "input_images_folder = unzipped_folder\n",
    "image_paths = [os.path.join(input_images_folder, img) for img in os.listdir(input_images_folder) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Split images into train and validation (80% train, 20% validation)\n",
    "train_images = image_paths[:int(0.8 * len(image_paths))]\n",
    "val_images = image_paths[int(0.8 * len(image_paths)):]\n",
    "\n",
    "# Function to save YOLO format labels (class_id x_center y_center width height)\n",
    "def save_yolo_labels(label_path, class_id, bbox, image_width, image_height):\n",
    "    if bbox is not None and len(bbox) > 0:  # Ensure there are bounding boxes\n",
    "        x_center = (bbox[0] + bbox[2]) / 2 / image_width\n",
    "        y_center = (bbox[1] + bbox[3]) / 2 / image_height\n",
    "        width = (bbox[2] - bbox[0]) / image_width\n",
    "        height = (bbox[3] - bbox[1]) / image_height\n",
    "        with open(label_path, \"a\") as f:\n",
    "            f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "        print(f\"Label saved for {label_path}: {class_id} {x_center} {y_center} {width} {height}\")\n",
    "    else:\n",
    "        print(f\"No bounding boxes found for {label_path}, skipping label.\")\n",
    "\n",
    "# Function to process images, run inference, and save results\n",
    "def process_images(image_paths, split):\n",
    "    for image_path in image_paths:\n",
    "        # Step 6: Run the large model to detect objects in the image (with GPU if available)\n",
    "        results = large_model(image_path)\n",
    "\n",
    "        # Check if any instances were detected\n",
    "        print(f\"Processing {image_path}, found {len(results[0].boxes)} instances.\")\n",
    "\n",
    "        # Extract image dimensions\n",
    "        img_name = os.path.basename(image_path)\n",
    "        img = results[0].orig_img\n",
    "        img_height, img_width = img.shape[:2]\n",
    "\n",
    "        # Save the image to the appropriate split folder (train/val)\n",
    "        output_image_path = f\"{base_path}/images/{split}/{img_name}\"\n",
    "        os.rename(image_path, output_image_path)\n",
    "\n",
    "        # Step 7: Filter results to only include \"fish\" category (class 2 based on your provided example)\n",
    "        fish_class_index = 2  # Update to class 2 for fish\n",
    "        for result in results:\n",
    "            for i, cls in enumerate(result.boxes.cls):\n",
    "                if cls == fish_class_index:  # Only keep fish detections\n",
    "                    bbox = result.boxes.xyxy[i].cpu().numpy()  # Bounding box (x1, y1, x2, y2)\n",
    "                    print(f\"Detected fish with bounding box: {bbox}\")\n",
    "                    print(f\"Image dimensions: {img_width}x{img_height}\")\n",
    "\n",
    "                    # Step 8: Save label file in YOLO format\n",
    "                    label_name = img_name.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "                    label_path = f\"{base_path}/labels/{split}/{label_name}\"\n",
    "\n",
    "                    # Save the bounding box in YOLO format (class_id = 0 for fish)\n",
    "                    save_yolo_labels(label_path, class_id=0, bbox=bbox, image_width=img_width, image_height=img_height)\n",
    "\n",
    "# Step 9: Process train and validation images (use a small sample for testing)\n",
    "print(\"Processing a small sample of training images to test label generation...\")\n",
    "sample_images = train_images[:5]  # Test with a few images first\n",
    "process_images(sample_images, \"train\")\n",
    "\n",
    "# Check if labels were generated\n",
    "train_labels = os.listdir(f\"{base_path}/labels/train\")\n",
    "print(f\"Generated labels for training set: {train_labels}\")\n",
    "\n",
    "print(\"Test complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Windows CUDA Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.8\n",
      "Available GPUs: 1\n",
      "Current GPU: 0\n",
      "GPU Name: Quadro P4000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.version.cuda)  # Should show 11.8 or similar\n",
    "print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "print(f\"GPU Name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "# For Windows Troubleshooting \n",
    "# run via cmd to check cuda version\n",
    "# nvcc --version\n",
    "# uninstall \n",
    "#(yolo8n_model_train) C:\\Users\\PICHLMRUser>pip uninstall torch torchvision torchaudio\n",
    "# reinstall\n",
    "#(yolo8n_model_train) C:\\Users\\PICHLMRUser>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FR-Y3oydaYZt",
    "YesCg-LraWJe",
    "NFcGFuT0ZxhG"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
